{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dded05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace Free Model\n",
    "Free_model_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "Free_model = ChatHuggingFace(llm=Free_model_endpoint)\n",
    "\n",
    "\n",
    "# ---------------- Utility: Extract Video ID ----------------\n",
    "def get_video_id_regex(url: str) -> str | None:\n",
    "    \"\"\"Extract YouTube video ID from normal and short links.\"\"\"\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# ---------------- Transcript Fetching ----------------\n",
    "def fetch(video_url: str):\n",
    "    \"\"\"Fetch transcript text from YouTube video.\"\"\"\n",
    "    video_id = get_video_id_regex(video_url)\n",
    "    if not video_id:\n",
    "        st.error(\"Invalid YouTube URL ‚Äî couldn't extract video ID.\")\n",
    "        return None\n",
    "    api = YouTubeTranscriptApi()\n",
    "    try:\n",
    "        transcript = api.fetch(video_id)\n",
    "        text = \" \".join([t.text for t in transcript])\n",
    "        return text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        st.error(\"Transcript not available for this video.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- Vector Store Creation ----------------\n",
    "def create_vector_store(text: str, model_type: str, openai_key: str = None):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    if model_type == \"paid\":\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_llm(model_type, openai_key=None):\n",
    "    if model_type == \"paid\":\n",
    "        return ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "    else:\n",
    "        return Free_model\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI ----------------\n",
    "st.title(\"üìΩÔ∏è YouTube Chat Bot \")\n",
    "st.write(\"Choose between **Paid (OpenAI)** or **Free (HuggingFace)** models.\")\n",
    "\n",
    "model_choice = st.radio(\"Select Model Type:\", (\"Paid (OpenAI)\", \"Free (HuggingFace)\"))\n",
    "\n",
    "if model_choice == \"Paid (OpenAI)\":\n",
    "    openai_api_key = st.text_input(\"Enter your OpenAI API Key:\", type=\"password\")\n",
    "else:\n",
    "    openai_api_key = None\n",
    "\n",
    "video_url = st.text_input(\"Enter YouTube Video URL:\")\n",
    "\n",
    "# -------- Process Transcript --------\n",
    "if st.button(\"Process Transcript\"):\n",
    "    if not video_url.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a valid YouTube video URL.\")\n",
    "    elif model_choice == \"Paid (OpenAI)\" and not openai_api_key.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API key for Paid model.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching transcript...\"):\n",
    "            transcript_text = fetch(video_url)\n",
    "\n",
    "        if transcript_text:\n",
    "            st.session_state.transcript = transcript_text\n",
    "            with st.spinner(\"Creating vector store...\"):\n",
    "                model_type = \"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\"\n",
    "                vector_store = create_vector_store(transcript_text, model_type, openai_key=openai_api_key)\n",
    "\n",
    "            st.session_state.vector_store = vector_store\n",
    "            st.success(\"‚úÖ Transcript processed and stored in memory!\")\n",
    "            st.write(f\"Number of chunks created: {len(vector_store.index_to_docstore_id)}\")\n",
    "\n",
    "# -------- Show Transcript --------\n",
    "if \"transcript\" in st.session_state:\n",
    "    st.subheader(\"üìú Transcript Preview\")\n",
    "    st.text_area(\"Transcript\", st.session_state.transcript[:3000], height=200)\n",
    "\n",
    "# -------- Chat Section --------\n",
    "st.subheader(\"üí¨ Chat with the Video\")\n",
    "query = st.text_input(\"Ask a question about the video:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if \"vector_store\" not in st.session_state:\n",
    "        st.error(\"‚ö†Ô∏è No transcript processed yet. Please process one first.\")\n",
    "    elif not query.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a question.\")\n",
    "    else:\n",
    "        retriever = st.session_state.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        llm = get_llm(\"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\", openai_key=openai_api_key)\n",
    "\n",
    "        # Prompt Template\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=(\n",
    "                \"You are an assistant that answers questions based on the provided transcript.\\n\"\n",
    "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Runnable Chain\n",
    "        chain = (\n",
    "            RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(getattr(response, \"content\", str(response)))\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace Free Model\n",
    "Free_model_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "Free_model = ChatHuggingFace(llm=Free_model_endpoint)\n",
    "\n",
    "\n",
    "# ---------------- Utility: Extract Video ID ----------------\n",
    "def get_video_id_regex(url: str) -> str | None:\n",
    "    \"\"\"Extract YouTube video ID from normal and short links.\"\"\"\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# ---------------- Transcript Fetching ----------------\n",
    "def fetch(video_url: str):\n",
    "    \"\"\"Fetch transcript text from YouTube video.\"\"\"\n",
    "    video_id = get_video_id_regex(video_url)\n",
    "    if not video_id:\n",
    "        st.error(\"Invalid YouTube URL ‚Äî couldn't extract video ID.\")\n",
    "        return None\n",
    "    api = YouTubeTranscriptApi()\n",
    "    try:\n",
    "        transcript = api.fetch(video_id)\n",
    "        text = \" \".join([t.text for t in transcript])\n",
    "        return text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        st.error(\"Transcript not available for this video.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- Vector Store Creation ----------------\n",
    "def create_vector_store(text: str, model_type: str, openai_key: str = None):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    if model_type == \"paid\":\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_llm(model_type, openai_key=None):\n",
    "    if model_type == \"paid\":\n",
    "        return ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "    else:\n",
    "        return Free_model\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI ----------------\n",
    "st.title(\"üìΩÔ∏è YouTube Chat Bot \")\n",
    "st.write(\"Choose between **Paid (OpenAI)** or **Free (HuggingFace)** models.\")\n",
    "\n",
    "model_choice = st.radio(\"Select Model Type:\", (\"Paid (OpenAI)\", \"Free (HuggingFace)\"))\n",
    "\n",
    "if model_choice == \"Paid (OpenAI)\":\n",
    "    openai_api_key = st.text_input(\"Enter your OpenAI API Key:\", type=\"password\")\n",
    "else:\n",
    "    openai_api_key = None\n",
    "\n",
    "video_url = st.text_input(\"Enter YouTube Video URL:\")\n",
    "\n",
    "# -------- Process Transcript --------\n",
    "if st.button(\"Process Transcript\"):\n",
    "    if not video_url.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a valid YouTube video URL.\")\n",
    "    elif model_choice == \"Paid (OpenAI)\" and not openai_api_key.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API key for Paid model.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching transcript...\"):\n",
    "            transcript_text = fetch(video_url)\n",
    "\n",
    "        if transcript_text:\n",
    "            st.session_state.transcript = transcript_text\n",
    "            with st.spinner(\"Creating vector store...\"):\n",
    "                model_type = \"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\"\n",
    "                vector_store = create_vector_store(transcript_text, model_type, openai_key=openai_api_key)\n",
    "\n",
    "            st.session_state.vector_store = vector_store\n",
    "            st.success(\"‚úÖ Transcript processed and stored in memory!\")\n",
    "            st.write(f\"Number of chunks created: {len(vector_store.index_to_docstore_id)}\")\n",
    "\n",
    "# -------- Show Transcript --------\n",
    "if \"transcript\" in st.session_state:\n",
    "    st.subheader(\"üìú Transcript Preview\")\n",
    "    st.text_area(\"Transcript\", st.session_state.transcript[:3000], height=200)\n",
    "\n",
    "# -------- Chat Section --------\n",
    "st.subheader(\"üí¨ Chat with the Video\")\n",
    "query = st.text_input(\"Ask a question about the video:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if \"vector_store\" not in st.session_state:\n",
    "        st.error(\"‚ö†Ô∏è No transcript processed yet. Please process one first.\")\n",
    "    elif not query.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a question.\")\n",
    "    else:\n",
    "        retriever = st.session_state.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        llm = get_llm(\"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\", openai_key=openai_api_key)\n",
    "\n",
    "        # Prompt Template\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=(\n",
    "                \"You are an assistant that answers questions based on the provided transcript.\\n\"\n",
    "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Runnable Chain\n",
    "        chain = (\n",
    "            RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(getattr(response, \"content\", str(response)))\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace Free Model\n",
    "Free_model_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "Free_model = ChatHuggingFace(llm=Free_model_endpoint)\n",
    "\n",
    "\n",
    "# ---------------- Utility: Extract Video ID ----------------\n",
    "def get_video_id_regex(url: str) -> str | None:\n",
    "    \"\"\"Extract YouTube video ID from normal and short links.\"\"\"\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# ---------------- Transcript Fetching ----------------\n",
    "def fetch(video_url: str):\n",
    "    \"\"\"Fetch transcript text from YouTube video.\"\"\"\n",
    "    video_id = get_video_id_regex(video_url)\n",
    "    if not video_id:\n",
    "        st.error(\"Invalid YouTube URL ‚Äî couldn't extract video ID.\")\n",
    "        return None\n",
    "    api = YouTubeTranscriptApi()\n",
    "    try:\n",
    "        transcript = api.fetch(video_id)\n",
    "        text = \" \".join([t.text for t in transcript])\n",
    "        return text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        st.error(\"Transcript not available for this video.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- Vector Store Creation ----------------\n",
    "def create_vector_store(text: str, model_type: str, openai_key: str = None):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    if model_type == \"paid\":\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_llm(model_type, openai_key=None):\n",
    "    if model_type == \"paid\":\n",
    "        return ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "    else:\n",
    "        return Free_model\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI ----------------\n",
    "st.title(\"üìΩÔ∏è YouTube Chat Bot \")\n",
    "st.write(\"Choose between **Paid (OpenAI)** or **Free (HuggingFace)** models.\")\n",
    "\n",
    "model_choice = st.radio(\"Select Model Type:\", (\"Paid (OpenAI)\", \"Free (HuggingFace)\"))\n",
    "\n",
    "if model_choice == \"Paid (OpenAI)\":\n",
    "    openai_api_key = st.text_input(\"Enter your OpenAI API Key:\", type=\"password\")\n",
    "else:\n",
    "    openai_api_key = None\n",
    "\n",
    "video_url = st.text_input(\"Enter YouTube Video URL:\")\n",
    "\n",
    "# -------- Process Transcript --------\n",
    "if st.button(\"Process Transcript\"):\n",
    "    if not video_url.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a valid YouTube video URL.\")\n",
    "    elif model_choice == \"Paid (OpenAI)\" and not openai_api_key.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API key for Paid model.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching transcript...\"):\n",
    "            transcript_text = fetch(video_url)\n",
    "\n",
    "        if transcript_text:\n",
    "            st.session_state.transcript = transcript_text\n",
    "            with st.spinner(\"Creating vector store...\"):\n",
    "                model_type = \"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\"\n",
    "                vector_store = create_vector_store(transcript_text, model_type, openai_key=openai_api_key)\n",
    "\n",
    "            st.session_state.vector_store = vector_store\n",
    "            st.success(\"‚úÖ Transcript processed and stored in memory!\")\n",
    "            st.write(f\"Number of chunks created: {len(vector_store.index_to_docstore_id)}\")\n",
    "\n",
    "# -------- Show Transcript --------\n",
    "if \"transcript\" in st.session_state:\n",
    "    st.subheader(\"üìú Transcript Preview\")\n",
    "    st.text_area(\"Transcript\", st.session_state.transcript[:3000], height=200)\n",
    "\n",
    "# -------- Chat Section --------\n",
    "st.subheader(\"üí¨ Chat with the Video\")\n",
    "query = st.text_input(\"Ask a question about the video:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if \"vector_store\" not in st.session_state:\n",
    "        st.error(\"‚ö†Ô∏è No transcript processed yet. Please process one first.\")\n",
    "    elif not query.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a question.\")\n",
    "    else:\n",
    "        retriever = st.session_state.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        llm = get_llm(\"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\", openai_key=openai_api_key)\n",
    "\n",
    "        # Prompt Template\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=(\n",
    "                \"You are an assistant that answers questions based on the provided transcript.\\n\"\n",
    "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Runnable Chain\n",
    "        chain = (\n",
    "            RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(getattr(response, \"content\", str(response)))\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace Free Model\n",
    "Free_model_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "Free_model = ChatHuggingFace(llm=Free_model_endpoint)\n",
    "\n",
    "\n",
    "# ---------------- Utility: Extract Video ID ----------------\n",
    "def get_video_id_regex(url: str) -> str | None:\n",
    "    \"\"\"Extract YouTube video ID from normal and short links.\"\"\"\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# ---------------- Transcript Fetching ----------------\n",
    "def fetch(video_url: str):\n",
    "    \"\"\"Fetch transcript text from YouTube video.\"\"\"\n",
    "    video_id = get_video_id_regex(video_url)\n",
    "    if not video_id:\n",
    "        st.error(\"Invalid YouTube URL ‚Äî couldn't extract video ID.\")\n",
    "        return None\n",
    "    api = YouTubeTranscriptApi()\n",
    "    try:\n",
    "        transcript = api.fetch(video_id)\n",
    "        text = \" \".join([t.text for t in transcript])\n",
    "        return text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        st.error(\"Transcript not available for this video.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- Vector Store Creation ----------------\n",
    "def create_vector_store(text: str, model_type: str, openai_key: str = None):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    if model_type == \"paid\":\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_llm(model_type, openai_key=None):\n",
    "    if model_type == \"paid\":\n",
    "        return ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "    else:\n",
    "        return Free_model\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI ----------------\n",
    "st.title(\"üìΩÔ∏è YouTube Chat Bot \")\n",
    "st.write(\"Choose between **Paid (OpenAI)** or **Free (HuggingFace)** models.\")\n",
    "\n",
    "model_choice = st.radio(\"Select Model Type:\", (\"Paid (OpenAI)\", \"Free (HuggingFace)\"))\n",
    "\n",
    "if model_choice == \"Paid (OpenAI)\":\n",
    "    openai_api_key = st.text_input(\"Enter your OpenAI API Key:\", type=\"password\")\n",
    "else:\n",
    "    openai_api_key = None\n",
    "\n",
    "video_url = st.text_input(\"Enter YouTube Video URL:\")\n",
    "\n",
    "# -------- Process Transcript --------\n",
    "if st.button(\"Process Transcript\"):\n",
    "    if not video_url.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a valid YouTube video URL.\")\n",
    "    elif model_choice == \"Paid (OpenAI)\" and not openai_api_key.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API key for Paid model.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching transcript...\"):\n",
    "            transcript_text = fetch(video_url)\n",
    "\n",
    "        if transcript_text:\n",
    "            st.session_state.transcript = transcript_text\n",
    "            with st.spinner(\"Creating vector store...\"):\n",
    "                model_type = \"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\"\n",
    "                vector_store = create_vector_store(transcript_text, model_type, openai_key=openai_api_key)\n",
    "\n",
    "            st.session_state.vector_store = vector_store\n",
    "            st.success(\"‚úÖ Transcript processed and stored in memory!\")\n",
    "            st.write(f\"Number of chunks created: {len(vector_store.index_to_docstore_id)}\")\n",
    "\n",
    "# -------- Show Transcript --------\n",
    "if \"transcript\" in st.session_state:\n",
    "    st.subheader(\"üìú Transcript Preview\")\n",
    "    st.text_area(\"Transcript\", st.session_state.transcript[:3000], height=200)\n",
    "\n",
    "# -------- Chat Section --------\n",
    "st.subheader(\"üí¨ Chat with the Video\")\n",
    "query = st.text_input(\"Ask a question about the video:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if \"vector_store\" not in st.session_state:\n",
    "        st.error(\"‚ö†Ô∏è No transcript processed yet. Please process one first.\")\n",
    "    elif not query.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a question.\")\n",
    "    else:\n",
    "        retriever = st.session_state.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        llm = get_llm(\"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\", openai_key=openai_api_key)\n",
    "\n",
    "        # Prompt Template\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=(\n",
    "                \"You are an assistant that answers questions based on the provided transcript.\\n\"\n",
    "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Runnable Chain\n",
    "        chain = (\n",
    "            RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(getattr(response, \"content\", str(response)))\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, VideoUnavailable\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# HuggingFace Free Model\n",
    "Free_model_endpoint = HuggingFaceEndpoint(\n",
    "    repo_id=\"google/gemma-2-2b-it\",\n",
    "    task=\"text-generation\"\n",
    ")\n",
    "Free_model = ChatHuggingFace(llm=Free_model_endpoint)\n",
    "\n",
    "\n",
    "# ---------------- Utility: Extract Video ID ----------------\n",
    "def get_video_id_regex(url: str) -> str | None:\n",
    "    \"\"\"Extract YouTube video ID from normal and short links.\"\"\"\n",
    "    match = re.search(r\"(?:v=|youtu\\.be/)([A-Za-z0-9_-]{11})\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# ---------------- Transcript Fetching ----------------\n",
    "def fetch(video_url: str):\n",
    "    \"\"\"Fetch transcript text from YouTube video.\"\"\"\n",
    "    video_id = get_video_id_regex(video_url)\n",
    "    if not video_id:\n",
    "        st.error(\"Invalid YouTube URL ‚Äî couldn't extract video ID.\")\n",
    "        return None\n",
    "    api = YouTubeTranscriptApi()\n",
    "    try:\n",
    "        transcript = api.fetch(video_id)\n",
    "        text = \" \".join([t.text for t in transcript])\n",
    "        return text\n",
    "    except (TranscriptsDisabled, NoTranscriptFound, VideoUnavailable):\n",
    "        st.error(\"Transcript not available for this video.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# ---------------- Vector Store Creation ----------------\n",
    "def create_vector_store(text: str, model_type: str, openai_key: str = None):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = splitter.split_text(text)\n",
    "\n",
    "    if model_type == \"paid\":\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
    "    else:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vector_store = FAISS.from_texts(chunks, embeddings)\n",
    "    return vector_store\n",
    "\n",
    "\n",
    "def get_llm(model_type, openai_key=None):\n",
    "    if model_type == \"paid\":\n",
    "        return ChatOpenAI(model=\"gpt-4\", openai_api_key=openai_key)\n",
    "    else:\n",
    "        return Free_model\n",
    "\n",
    "\n",
    "# ---------------- Streamlit UI ----------------\n",
    "st.title(\"üìΩÔ∏è YouTube Chat Bot \")\n",
    "st.write(\"Choose between **Paid (OpenAI)** or **Free (HuggingFace)** models.\")\n",
    "\n",
    "model_choice = st.radio(\"Select Model Type:\", (\"Paid (OpenAI)\", \"Free (HuggingFace)\"))\n",
    "\n",
    "if model_choice == \"Paid (OpenAI)\":\n",
    "    openai_api_key = st.text_input(\"Enter your OpenAI API Key:\", type=\"password\")\n",
    "else:\n",
    "    openai_api_key = None\n",
    "\n",
    "video_url = st.text_input(\"Enter YouTube Video URL:\")\n",
    "\n",
    "# -------- Process Transcript --------\n",
    "if st.button(\"Process Transcript\"):\n",
    "    if not video_url.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a valid YouTube video URL.\")\n",
    "    elif model_choice == \"Paid (OpenAI)\" and not openai_api_key.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter your OpenAI API key for Paid model.\")\n",
    "    else:\n",
    "        with st.spinner(\"Fetching transcript...\"):\n",
    "            transcript_text = fetch(video_url)\n",
    "\n",
    "        if transcript_text:\n",
    "            st.session_state.transcript = transcript_text\n",
    "            with st.spinner(\"Creating vector store...\"):\n",
    "                model_type = \"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\"\n",
    "                vector_store = create_vector_store(transcript_text, model_type, openai_key=openai_api_key)\n",
    "\n",
    "            st.session_state.vector_store = vector_store\n",
    "            st.success(\"‚úÖ Transcript processed and stored in memory!\")\n",
    "            st.write(f\"Number of chunks created: {len(vector_store.index_to_docstore_id)}\")\n",
    "\n",
    "# -------- Show Transcript --------\n",
    "if \"transcript\" in st.session_state:\n",
    "    st.subheader(\"üìú Transcript Preview\")\n",
    "    st.text_area(\"Transcript\", st.session_state.transcript[:3000], height=200)\n",
    "\n",
    "# -------- Chat Section --------\n",
    "st.subheader(\"üí¨ Chat with the Video\")\n",
    "query = st.text_input(\"Ask a question about the video:\")\n",
    "\n",
    "if st.button(\"Get Answer\"):\n",
    "    if \"vector_store\" not in st.session_state:\n",
    "        st.error(\"‚ö†Ô∏è No transcript processed yet. Please process one first.\")\n",
    "    elif not query.strip():\n",
    "        st.error(\"‚ö†Ô∏è Please enter a question.\")\n",
    "    else:\n",
    "        retriever = st.session_state.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        llm = get_llm(\"paid\" if model_choice == \"Paid (OpenAI)\" else \"free\", openai_key=openai_api_key)\n",
    "\n",
    "        # Prompt Template\n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            template=(\n",
    "                \"You are an assistant that answers questions based on the provided transcript.\\n\"\n",
    "                \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Runnable Chain\n",
    "        chain = (\n",
    "            RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "            | prompt\n",
    "            | llm\n",
    "        )\n",
    "\n",
    "        with st.spinner(\"Generating answer...\"):\n",
    "            response = chain.invoke(query)\n",
    "\n",
    "        st.markdown(\"**Answer:**\")\n",
    "        st.write(getattr(response, \"content\", str(response)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666b31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
